{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN  Word and Name Generator - Alejandro",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB7X8CJOnSYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u14YnvVan7F2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e93c03be-161b-4453-c3b7-6073d1fe968f"
      },
      "source": [
        "with open('/content/drive/My Drive/Data/HungerGamex.txt', 'r') as myFile:\n",
        "  text = myFile.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i)\n",
        "  for i, c in enumerate(chars))\n",
        "indicies_char = dict((i, c)\n",
        "  for i, c in enumerate(chars))\n",
        "'corpus length: {} total chars: {}'.format(len(text), len(chars))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'corpus length: 545112 total chars: 81'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHA2zbIipa-J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "0cdfee17-7c5a-4612-b514-7b5a3758e88f"
      },
      "source": [
        "print(text[:500])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For James Proimos \n",
            "\n",
            "\n",
            "\n",
            "PARTI \n",
            "\n",
            "THE TRIBUTES \n",
            "\n",
            "\n",
            "\n",
            "When I wake up, the other side of the bed is cold. My finÂ¬ \n",
            "gers stretch out, seeking Prim's warmth but finding only the \n",
            "rough canvas cover of the mattress. She must have had bad \n",
            "dreams and climbed in with our mother. Of course, she did. \n",
            "This is the day of the reaping. \n",
            "\n",
            "I prop myself up on one elbow. There's enough light in the \n",
            "bedroom to see them. My little sister, Prim, curled up on her \n",
            "side, cocooned in my mother's body, their cheeks presse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeTzrnk1pmAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1396f17c-e794-4603-92f2-c196bc03e35e"
      },
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range (0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 181691\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9VefRDD1QNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "bb869b56-592f-4a33-86e4-5ad42f17803f"
      },
      "source": [
        "print(sentences[0:20])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['For James Proimos \\n\\n\\n\\nPARTI \\n\\nTHE TRIBUT', ' James Proimos \\n\\n\\n\\nPARTI \\n\\nTHE TRIBUTES ', 'mes Proimos \\n\\n\\n\\nPARTI \\n\\nTHE TRIBUTES \\n\\n\\n', ' Proimos \\n\\n\\n\\nPARTI \\n\\nTHE TRIBUTES \\n\\n\\n\\nWh', 'oimos \\n\\n\\n\\nPARTI \\n\\nTHE TRIBUTES \\n\\n\\n\\nWhen ', 'os \\n\\n\\n\\nPARTI \\n\\nTHE TRIBUTES \\n\\n\\n\\nWhen I w', '\\n\\n\\n\\nPARTI \\n\\nTHE TRIBUTES \\n\\n\\n\\nWhen I wake', '\\nPARTI \\n\\nTHE TRIBUTES \\n\\n\\n\\nWhen I wake up', 'RTI \\n\\nTHE TRIBUTES \\n\\n\\n\\nWhen I wake up, t', ' \\n\\nTHE TRIBUTES \\n\\n\\n\\nWhen I wake up, the ', 'THE TRIBUTES \\n\\n\\n\\nWhen I wake up, the oth', ' TRIBUTES \\n\\n\\n\\nWhen I wake up, the other ', 'IBUTES \\n\\n\\n\\nWhen I wake up, the other sid', 'TES \\n\\n\\n\\nWhen I wake up, the other side o', ' \\n\\n\\n\\nWhen I wake up, the other side of t', '\\n\\nWhen I wake up, the other side of the ', 'hen I wake up, the other side of the bed', ' I wake up, the other side of the bed is', 'wake up, the other side of the bed is co', 'e up, the other side of the bed is cold.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNA4e8bp1Ven",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    X[i, t, char_indices[char]] = 1\n",
        "  y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF3fw5bC2A-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-I8gLrv3Fkj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c842d927-84f8-43ac-ef62-e86d6022b42e"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "callbacks = [EarlyStopping(monitor=\"loss\", patience=2),\n",
        "            ModelCheckpoint(filepath=\"bestmodel.h5\", monitor=\"loss\", save_best_only=True)]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               107520    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 81)                10449     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 81)                0         \n",
            "=================================================================\n",
            "Total params: 117,969\n",
            "Trainable params: 117,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXZO_rS4D6VS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a65287d4-e8f6-4660-b6fb-95f4a0d05ca2"
      },
      "source": [
        "epochs = 40\n",
        "batch_size = 128\n",
        "model.fit(X, y, batch_size=batch_size, epochs=epochs, callbacks=callbacks)\n",
        "model.save_weights(\"/content/drive/My Drive/Data/lotr_weights/lotr_lstm_weights.h5\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2778\n",
            "Epoch 2/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2751\n",
            "Epoch 3/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2735\n",
            "Epoch 4/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2689\n",
            "Epoch 5/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2701\n",
            "Epoch 6/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2667\n",
            "Epoch 7/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2650\n",
            "Epoch 8/40\n",
            "1420/1420 [==============================] - 8s 6ms/step - loss: 1.2630\n",
            "Epoch 9/40\n",
            "1420/1420 [==============================] - 8s 6ms/step - loss: 1.2616\n",
            "Epoch 10/40\n",
            "1420/1420 [==============================] - 9s 6ms/step - loss: 1.2605\n",
            "Epoch 11/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2590\n",
            "Epoch 12/40\n",
            "1420/1420 [==============================] - 9s 6ms/step - loss: 1.2582\n",
            "Epoch 13/40\n",
            "1420/1420 [==============================] - 9s 6ms/step - loss: 1.2532\n",
            "Epoch 14/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2520\n",
            "Epoch 15/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2482\n",
            "Epoch 16/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2504\n",
            "Epoch 17/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2470\n",
            "Epoch 18/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2451\n",
            "Epoch 19/40\n",
            "1420/1420 [==============================] - 10s 7ms/step - loss: 1.2441\n",
            "Epoch 20/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2421\n",
            "Epoch 21/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2416\n",
            "Epoch 22/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2410\n",
            "Epoch 23/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2388\n",
            "Epoch 24/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2376\n",
            "Epoch 25/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2388\n",
            "Epoch 26/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2343\n",
            "Epoch 27/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2338\n",
            "Epoch 28/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2359\n",
            "Epoch 29/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2328\n",
            "Epoch 30/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2305\n",
            "Epoch 31/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2308\n",
            "Epoch 32/40\n",
            "1420/1420 [==============================] - 9s 7ms/step - loss: 1.2321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QRbplMvFFzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random \n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1, preds, 1)\n",
        "  return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wFflBchIyZg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "127c7d68-ef9c-4d9a-f742-617357e452b8"
      },
      "source": [
        "import sys \n",
        "\n",
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "\n",
        "for diversity in [0.2, 0.5, 1.0]:\n",
        "  print()\n",
        "  print('-----diversity:', diversity)\n",
        "  generated = ''\n",
        "  sentence = text[start_index: start_index + maxlen]\n",
        "  generated += sentence\n",
        "  print('------Generated with seed: \"' + sentence + '\"')\n",
        "  sys.stdout.write(generated)\n",
        "  for i in range(400):\n",
        "    x = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x[0, t, char_indices[char]] = 1.\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_index = sample(preds, diversity)\n",
        "    next_char = indicies_char[next_index]\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "  print()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-----diversity: 0.2\n",
            "------Generated with seed: \"a relief to be alone with Cinna, to feel\"\n",
            "a relief to be alone with Cinna, to feel a sort of the \n",
            "pair of the \n",
            "supplies to c"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "an see the \n",
            "stinges and seems to the stream \n",
            "with the stream and seems to care the \n",
            "part of the \n",
            "legs and had and I can't stare a stream and the pack and \n",
            "she's a straight and the stream and the stream and then well the stream and find a straight of the \n",
            "part of the \n",
            "pair of the \n",
            "stinges and he and I think the \n",
            "same something and \n",
            "she's a stream and \n",
            "she's\n",
            "\n",
            "-----diversity: 0.5\n",
            "------Generated with seed: \"a relief to be alone with Cinna, to feel\"\n",
            "a relief to be alone with Cinna, to feel better the boy from District \n",
            "ing \n",
            "about the rain. The same sleeping bag with my \n",
            "father and saddep the cheese stares the same lose it is so as I spread and he was a suppled out a but the \n",
            "Games berow me and I didn't see the stinged in the \n",
            "train and the way \n",
            "the hard are have to guess is sense. \n",
            "\n",
            "I can see the boy from District \n",
            "ided the \n",
            "room. Someone if I always and the train has been a few st\n",
            "\n",
            "-----diversity: 1.0\n",
            "------Generated with seed: \"a relief to be alone with Cinna, to feel\"\n",
            "a relief to be alone with Cinna, to feel campwed of plans Cato can still I can see for my place. And I'll knew the arfaciPpu a walt better in my fingers and in, but there is sylred secoHyid entire up from the stream a bow as and confused it, \n",
            "berac still formed on the buydred seeing out to brise the offer's trees. Now the presentable close if he bite victorits, I couldn't care on thoughtoces towire a blinking in rabbit. \n",
            "\n",
            "still hir cann\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fevbe1QPNufL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}